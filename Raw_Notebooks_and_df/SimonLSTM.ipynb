{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily Returns</th>\n",
       "      <th>50 Day MA</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Trading Signal</th>\n",
       "      <th>Entry/Exit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>27.930000</td>\n",
       "      <td>27.940001</td>\n",
       "      <td>27.290001</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>21.864422</td>\n",
       "      <td>76672400</td>\n",
       "      <td>-0.016804</td>\n",
       "      <td>27.9144</td>\n",
       "      <td>28.636182</td>\n",
       "      <td>26.778219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.070000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>21.665649</td>\n",
       "      <td>83939700</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>27.9386</td>\n",
       "      <td>28.268699</td>\n",
       "      <td>26.919901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>27.209999</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>26.950001</td>\n",
       "      <td>27.230000</td>\n",
       "      <td>21.649748</td>\n",
       "      <td>56766200</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>27.9454</td>\n",
       "      <td>28.224377</td>\n",
       "      <td>26.951022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>27.040001</td>\n",
       "      <td>27.330000</td>\n",
       "      <td>26.950001</td>\n",
       "      <td>26.959999</td>\n",
       "      <td>21.561775</td>\n",
       "      <td>44116500</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>27.9442</td>\n",
       "      <td>27.959069</td>\n",
       "      <td>26.945130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>27.070000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>27.020000</td>\n",
       "      <td>21.609766</td>\n",
       "      <td>70817900</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>27.9478</td>\n",
       "      <td>28.004014</td>\n",
       "      <td>26.963787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2011-02-10  27.930000  27.940001  27.290001  27.500000  21.864422   \n",
       "1  2011-02-11  27.760000  27.809999  27.070000  27.250000  21.665649   \n",
       "2  2011-02-14  27.209999  27.270000  26.950001  27.230000  21.649748   \n",
       "3  2011-02-15  27.040001  27.330000  26.950001  26.959999  21.561775   \n",
       "4  2011-02-16  27.049999  27.070000  26.600000  27.020000  21.609766   \n",
       "\n",
       "     Volume  Daily Returns  50 Day MA      Upper      Lower  Trading Signal  \\\n",
       "0  76672400      -0.016804    27.9144  28.636182  26.778219             1.0   \n",
       "1  83939700      -0.009091    27.9386  28.268699  26.919901             1.0   \n",
       "2  56766200      -0.000734    27.9454  28.224377  26.951022             1.0   \n",
       "3  44116500      -0.009916    27.9442  27.959069  26.945130             1.0   \n",
       "4  70817900       0.002226    27.9478  28.004014  26.963787             1.0   \n",
       "\n",
       "   Entry/Exit  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('MSFT_df.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "dataset_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27.93000031],\n",
       "       [ 27.76000023],\n",
       "       [ 27.20999908],\n",
       "       ...,\n",
       "       [214.8500061 ],\n",
       "       [214.1000061 ],\n",
       "       [214.50999451]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-de3362cbf3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Creating a data structure with 60 timesteps and 1 output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Use 70% of the data for training and the remaineder for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "df2 = dataset_train.copy()\n",
    "X = df2.drop([\"Entry/Exit\"], inplace=True, axis=1)\n",
    "y = dataset_train[[\"Entry/Exit\"]]\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "\n",
    "#X_train = []\n",
    "#y_train = []\n",
    "#for i in range(60, 2035):\n",
    "   # X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    #y_train.append(training_set_scaled[i, 0])\n",
    "#X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0032\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 6.5077e-04\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 4.7480e-04\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 3.9614e-04\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 4.7226e-04\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 4.3509e-04\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 5s 75ms/step - loss: 4.6157e-04\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 3.7325e-04\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 4.1194e-04\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 3.5850e-04\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 3.6364e-04\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 3.1424e-04\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 3.3619e-04\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 3.6378e-04\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 3.0606e-04\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 3.3375e-04\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 3.0172e-04\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.8923e-04\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 3.6646e-04\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.4590e-04\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 2.9472e-04\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.7311e-04\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.7433e-04\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.7040e-04\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 3.0576e-04\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.5671e-04\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.8849e-04\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.5239e-04\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 2.1515e-04\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 2.3788e-04\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.6268e-04\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.9350e-04\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.8199e-04\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.2824e-04\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.6063e-04\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.3761e-04\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.4586e-04\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.5797e-04\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.0905e-04\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.4974e-04\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.0657e-04\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.2416e-04\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.2411e-04\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.0329e-04\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.4952e-04\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.3510e-04\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 5s 75ms/step - loss: 2.0048e-04\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.2326e-04\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.1561e-04\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.0800e-04\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.5960e-04\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.3266e-04\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.0175e-04\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 2.0320e-04\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 5s 75ms/step - loss: 2.1692e-04\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.0374e-04\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.8377e-04\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 2.4023e-04\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 2.0159e-04\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.6346e-04\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 5s 77ms/step - loss: 2.0746e-04\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.8545e-04\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9948e-04\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 1.9295e-04\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 1.9018e-04\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.0781e-04\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 1.8186e-04\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 1.8478e-04\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.1011e-04\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9819e-04\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.0508e-04\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 1.8839e-04\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.1125e-04\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9687e-04\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 1.9313e-04\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.1912e-04\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 1.7692e-04\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.7866e-04\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 4s 73ms/step - loss: 1.6982e-04\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9670e-04\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 1.6455e-04\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 4s 72ms/step - loss: 2.0450e-04\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 1.7763e-04\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.8656e-04\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9819e-04\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 4s 73ms/step - loss: 1.9663e-04\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.6536e-04\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.7132e-04\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.7001e-04\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 1.7938e-04\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 2.0433e-04\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9247e-04\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 2.2077e-04\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.7986e-04\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9130e-04\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.5197e-04\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 2.0271e-04\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.9488e-04\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 1.6594e-04\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 1.6056e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cfbb04bc50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'tatatest.csv' does not exist: b'tatatest.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-abab657ad0f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Getting the real stock price of 2017\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tatatest.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mreal_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'tatatest.csv' does not exist: b'tatatest.csv'"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv]",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
